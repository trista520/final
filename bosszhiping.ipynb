{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import urllib3\n",
    "from lxml import etree\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#職業详情\n",
    "def get_one_page(url):\n",
    "    http = urllib3.PoolManager(timeout=2)\n",
    "    urllib3.disable_warnings()\n",
    "    response = http.request('get', url)\n",
    "    html = response.data\n",
    "    selector = etree.HTML(html)\n",
    "    detail=selector.xpath(\"/html/body/div/div[3]/div/div[2]/ul/li\")\n",
    "    info=[]\n",
    "    job_title=selector.xpath(\"//li/div/div/h3/a/div[@class='job-title']/text()\")\n",
    "    yearly_salary=selector.xpath(\"//li/div/div/h3/a/span/text()\")\n",
    "    place=selector.xpath(\"//li/div/div[1]/p/text()[1]\")\n",
    "    seniority=selector.xpath(\"//li/div/div[1]/p/text()[2]\")\n",
    "    degree=selector.xpath(\"//li/div/div[1]/p/text()[3]\")\n",
    "    description=selector.xpath(\"//li/div/div[1]/h3/a/div[2]/div[2]/div[2]/text()\")\n",
    "    for i in range(0,len(detail)):\n",
    "        info.append([job_title[i],yearly_salary[i],place[i],seniority[i],degree[i]])\n",
    "    return info\n",
    "\n",
    "def get_one_page_description(url):\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(url)\n",
    "    driver.set_window_size(10000,5080)#设置窗口宽度，以免浮出的窗口超出范围\n",
    "    chain = ActionChains(driver)#联动鼠标\n",
    "    descriptions=[]\n",
    "    for i in range(1,31):\n",
    "        stop=driver.find_element_by_xpath( \"/html/body/div/div[3]/div/div[2]/ul/li[\"+ str(i) + \"]/div/div[1]/h3/a/div[1]\" )\n",
    "        chain.move_to_element(stop).perform()#停留鼠标\n",
    "        sleep(1)\n",
    "        description=driver.find_element_by_xpath(\"//html/body/div/div[3]/div/div[2]/ul/li[\"+ str(i) + \"]/div/div[1]/h3/a/div[2]/div[2]/div[2]\").text\n",
    "        descriptions.append(description)\n",
    "        driver.refresh\n",
    "    return descriptions\n",
    "\n",
    "def get_all_pages(url_list):\n",
    "    all_info=[]\n",
    "    for url in url_list:\n",
    "        info=get_one_page(url)\n",
    "        for i in info:\n",
    "            all_info.append(i)\n",
    "    return all_info \n",
    "\n",
    "def get_all_descriptions(url_list):\n",
    "    all_descriptions=[]\n",
    "    for url in url_list:\n",
    "        des=get_one_page_description(url)\n",
    "        for i in des:\n",
    "            all_descriptions.append(i)\n",
    "    return all_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_list=['https://www.zhipin.com/i100003-c100010000/?page=',\n",
    "               'https://www.zhipin.com/i100101-c100010000/?page=',\n",
    "               'https://www.zhipin.com/c100010000-p140101/?page=',\n",
    "               'https://www.zhipin.com/i100012-c100010000/?page=',\n",
    "               'https://www.zhipin.com/i100009-c100010000/?page=',\n",
    "               'https://www.zhipin.com/i100011-c100010000/?page=',\n",
    "              'https://www.zhipin.com/c100010000/e_102/?page=']\n",
    "url_list=[]\n",
    "for i in range(1,11):\n",
    "    for base_url in base_url_list:\n",
    "        url=base_url+str(i)\n",
    "        url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs=get_all_pages(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2059"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('jobs_info_media.csv','w',newline='') as g:\n",
    "    writer = csv.writer(g)\n",
    "    header = ['job_title','yearly_salary','place','seniority','degree']\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(all_jobs)\n",
    "len(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('jobs_info_media.csv',encoding ='gbk') \n",
    "df=df.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
